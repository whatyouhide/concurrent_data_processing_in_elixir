# Broadway

```elixir
Mix.install([
  {:broadway, "~> 1.0"},
  {:req, "~> 0.3"},
  {:kino, "~> 0.9.1"},
  {:kino_vega_lite, "~> 0.1.8"}
])

ExUnit.start(autorun: false)

import ExUnit.Assertions
```

## Overview

### The Goal

The goal of Broadway is to simplify data processing pipelines by providing the right abstractions

### Broadway Components

These are components that make up a Broadway pipeline:

* Producers
* Processors
* Batchers and batch processors

## Simple Pipeline: Producer and Processors

<!-- Learn more at https://mermaid-js.github.io/mermaid -->

```mermaid
%%{init: {'theme':'forest'}}%%
flowchart TD
  subgraph Producers
    prod1([Producer 1])
    prod2([Producer 2])
  end

  subgraph Processors
    proc1([Processor 1])
    proc2([Processor 2])
    proc3([Processor 3])
  end

  prod1 & prod2 --> proc1 & proc2 & proc3
```

<!-- livebook:{"break_markdown":true} -->

A Broadway producer is a **GenStage producer** that emits `%Broadway.Message{}`s as events.

Let's start with a producer that producers "synthetic" metrics:

```elixir
defmodule SyntheticMetricsProducer do
  use GenStage

  def start_link(options) do
    GenStage.start_link(__MODULE__, options)
  end

  @impl true
  def init(_options) do
    {:producer, :no_state}
  end

  @impl true
  def handle_demand(demand, state) do
    events =
      Stream.repeatedly(fn ->
        %Broadway.Message{
          data: %{
            method: Enum.random(["GET", "POST", "PUT", "DELETE"]),
            endpoint: Enum.random(["/posts", "/authors"]),
            request_time: (:rand.normal() * 500) |> abs() |> round()
          },
          acknowledger: Broadway.NoopAcknowledger.init()
        }
      end)

    {:noreply, Enum.take(events, demand), state}
  end
end

# Test:
{:ok, producer} = Kino.start_child(SyntheticMetricsProducer)

[{producer, max_demand: 5}]
|> GenStage.stream()
|> Enum.take(3)
|> Enum.each(fn message ->
  assert is_integer(message.data.request_time)
end)

Kino.terminate_child(producer)
```

Now, let's create a Broadway pipeline that consumes metrics, and for now **logs** the ones where `request_time` is greater than 500ms.

```elixir
defmodule SlowRequestsPipeline do
  use Broadway

  require Logger

  def start_link(opts) do
    chart = Keyword.fetch!(opts, :chart)

    Broadway.start_link(__MODULE__,
      name: __MODULE__,
      producer: [
        module: {SyntheticMetricsProducer, []},
        concurrency: 3,
        rate_limiting: [allowed_messages: 10, interval: 100]
      ],
      processors: [
        default: [concurrency: 2]
      ],
      context: %{chart: chart}
    )
  end

  @impl true
  def handle_message(:default, %Broadway.Message{} = message, _context = %{chart: chart}) do
    if message.data.request_time >= 500 do
      Logger.info("Slow request: #{inspect(message.data)}")

      Kino.VegaLite.push(chart, %{
        time: System.system_time(:millisecond),
        request_time: message.data.request_time
      })
    end

    message
  end
end
```

```elixir
alias VegaLite, as: VL

chart =
  VL.new(width: 800, height: 400)
  |> VL.mark(:line)
  |> VL.encode_field(:x, "time",
    title: "Time",
    type: :temporal,
    time_unit: "hoursminutessecondsmilliseconds"
  )
  |> VL.encode_field(:y, "request_time", title: "Request time (ms)", type: :quantitative)
  |> Kino.VegaLite.new()
  |> Kino.render()

{:ok, pipeline} = Kino.start_child({SlowRequestsPipeline, chart: chart})

Process.sleep(5_000)

Kino.terminate_child(pipeline)
```

Wanna see the topology of a Broadway supervision tree? ðŸ˜Ž

```elixir
{:ok, pipeline} = Kino.start_child({SlowRequestsPipeline, chart: chart})

# Internal API - DO NOT USE!
Kino.Process.render_sup_tree(:sys.get_state(pipeline).supervisor_pid, direction: :left_right)

Kino.terminate_child(pipeline)
```

## Batching

* Batch messages based on their properties.
* Process batches once they reach a **maximum size**, or a **timeout** expires.

<!-- livebook:{"break_markdown":true} -->

<!-- Learn more at https://mermaid-js.github.io/mermaid -->

```mermaid
%%{init: {'theme':'forest'}}%%
flowchart TD
  subgraph Producers
    prod1([Producer 1])
    prod2([Producer 2])
  end

  subgraph Processors
    proc1([Processor 1])
    proc2([Processor 2])
    proc3([Processor 3])
  end

  subgraph Batchers
    batcher_get([Batcher_GET])
    batcher_post([Batcher_POST])
    batcher_other([Batcher_other])
  end

  subgraph Batcher Processors
    batcher_get_proc1([Batcher_GET Processor 1])
    batcher_get_proc2([Batcher_GET Processor 2])
    batcher_other_proc1([Batcher_other Processor 1])
    batcher_other_proc2([Batcher_other Processor 2])
  end

  prod1 & prod2 --> proc1 & proc2 & proc3
  Processors --> batcher_get & batcher_post & batcher_other

  batcher_get --> batcher_get_proc1 & batcher_get_proc2
  batcher_other --> batcher_other_proc1 & batcher_other_proc2
```

<!-- livebook:{"break_markdown":true} -->

Let's implement a Broadway pipeline that aggregates requests and then sends the slowest requests down to a metrics provider (think [AppSignal](https://www.appsignal.com/) or [New Relic](https://newrelic.com/)).

```elixir
defmodule RequestsAggregatorPipeline do
  use Broadway

  require Logger

  def start_link([] = _opts) do
    Broadway.start_link(__MODULE__,
      name: __MODULE__,
      producer: [
        module: {SyntheticMetricsProducer, []},
        concurrency: 2,
        rate_limiting: [allowed_messages: 1000, interval: 1_000]
      ],
      processors: [
        default: [concurrency: 3]
      ],
      batchers: [
        GET: [
          batch_size: 1_000,
          batch_timeout: 500,
          concurrency: 3
        ],
        POST: [
          batch_size: 100,
          batch_timeout: 500,
          concurrency: 1
        ],
        other: [
          batch_size: 500,
          batch_timeout: 500,
          concurrency: 1
        ]
      ]
    )
  end

  @impl true
  def handle_message(:default, message, _context) do
    case message.data.method do
      "GET" -> Broadway.Message.put_batcher(message, :GET)
      "POST" -> Broadway.Message.put_batcher(message, :POST)
      _other -> Broadway.Message.put_batcher(message, :other)
    end
  end

  @impl true
  def handle_batch(batcher, messages, batch_info, _context) do
    slowest = Enum.max_by(messages, & &1.data.request_time)

    Logger.info(
      "Slowest request in #{inspect(batcher)} batch (out of #{batch_info.size}): #{inspect(slowest.data)}"
    )

    messages
  end
end
```

```elixir
{:ok, pipeline} = Kino.start_child(RequestsAggregatorPipeline)

Process.sleep(2_000)

Kino.terminate_child(pipeline)
```

Let's look at the new supervision tree.

```elixir
{:ok, pipeline} = Kino.start_child(RequestsAggregatorPipeline)

# Internal API - DO NOT USE!
Kino.Process.render_sup_tree(:sys.get_state(pipeline).supervisor_pid)

Kino.terminate_child(pipeline)
```
